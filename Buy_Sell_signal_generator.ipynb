{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1922c21-0354-44ef-b094-ba0e99b332fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conversation opened. 1 unread message.\n",
    "\n",
    "Skip to content\n",
    "Using Gmail with screen readers\n",
    "1 of 20,559\n",
    "Engine\n",
    "Inbox\n",
    "\n",
    "JOSE THOMAS\n",
    "2:53â€¯PM (0 minutes ago)\n",
    "to me\n",
    "\n",
    "import pandas as pd\n",
    "import os, shutil, glob\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "file_list1 = glob.glob('D:/CM_NSE/UDIFF/*.csv')\n",
    "\n",
    "final_df1 = pd.DataFrame() #empty dataframe\n",
    "\n",
    "for csv_file in file_list1:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df.columns = df.columns.str.replace(' ', '')\n",
    "    df = df.rename(columns={'TradDt': 'TIMESTAMP'})\n",
    "\n",
    "    df['TIMESTAMP'] = pd.to_datetime(df['TIMESTAMP'])\n",
    "    #df.set_index(['TIMESTAMP'], inplace=True)\n",
    "\n",
    "    df_trim = df.apply(lambda x: x.str.strip() if x.dtype == 'object' else x)\n",
    "    new_df = df_trim[df_trim['SctySrs'].isin(['EQ'])] \n",
    "    final_df1 = pd.concat([final_df1, new_df])\n",
    "\n",
    "final_df1=final_df1[['TIMESTAMP','TckrSymb','OpnPric','HghPric','LwPric','ClsPric']]\n",
    "final_df1.set_index(['TIMESTAMP'], inplace=True)\n",
    "final_df1.sort_index(inplace=True)\n",
    "final_df1 = final_df1.rename(columns={'TradDt': 'TIMESTAMP','TckrSymb':'SYMBOL','OpnPric':'OPEN','HghPric':'HIGH','LwPric':'LOW','ClsPric':'CLOSE'})\n",
    "\n",
    "\n",
    "dfs1 = {}\n",
    "\n",
    "for name, group in final_df1.groupby('SYMBOL'):\n",
    "    df_ts = group[['SYMBOL','OPEN','HIGH','LOW','CLOSE']]\n",
    "    # add the dataframe to the dictionary\n",
    "    dfs1[name] = df_ts\n",
    "    \n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file_path = 'D:/CM_NSE/FNO.csv'  \n",
    "csv_data = pd.read_csv(csv_file_path)\n",
    "symbols_from_csv = set(csv_data['SYMBOL'])\n",
    "\n",
    "\n",
    "\n",
    "# Filter the dictionary based on symbols in the CSV\n",
    "dfs1_filtered = {symbol: df for symbol, df in dfs1.items() if symbol in symbols_from_csv}\n",
    "\n",
    "for symbol, data in dfs1_filtered.items():\n",
    "    # Shift the 'OPEN' column by -1 to get the next day's opening price\n",
    "    CLOSE = data['CLOSE']\n",
    "    \n",
    "    # Use the latest available closing value as the 'last day's close'\n",
    "    last_day_close = data['CLOSE'].iloc[-1]  # This fetches the last available closing value\n",
    "    \n",
    "    # Calculate the percentage difference between next day's open and the last available close\n",
    "    data['Percentage_Difference'] = round((( last_day_close - CLOSE ) / CLOSE) * 100,2)\n",
    "    # Create a column for the latest closing price\n",
    "    data['Latest_Close_Price'] = last_day_close\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Update the dictionary with the modified DataFrame\n",
    "    dfs1_filtered[symbol] = data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "std_dev_multiplier = 2  # Multiplier for the standard deviation\n",
    "\n",
    "for symbol, data in dfs1_filtered.items():\n",
    "    df = pd.DataFrame()\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Calculate 5-period simple moving average (SMA) of the bar's midpoints\n",
    "    df['midpoint'] = (df['HIGH'] + df['LOW']) / 2\n",
    "    df['SMA_5'] = df['midpoint'].rolling(window=5).mean()\n",
    "\n",
    "    # Calculate 34-period simple moving average (SMA) of the bar's midpoints\n",
    "    df['SMA_34'] = df['midpoint'].rolling(window=34).mean()\n",
    "\n",
    "    # Calculate the Awesome Oscillator (AO) as the difference between the 5-period SMA and 34-period SMA\n",
    "    df['Awesome_Oscillator'] = df['SMA_5'] - df['SMA_34']\n",
    "\n",
    "    # Optional: You can also calculate a moving average of the Awesome Oscillator for smoother signals\n",
    "    # Here, we'll use a 5-period simple moving average\n",
    "    df['AO_SMA'] = df['Awesome_Oscillator'].rolling(window=5).mean()\n",
    "\n",
    "    # Generate buy/sell signals based on Awesome Oscillator\n",
    "    df['Buy_Signal'] = (df['Awesome_Oscillator'] > df['AO_SMA']) & (df['Awesome_Oscillator'].shift(1) < df['AO_SMA'].shift(1))\n",
    "    df['Sell_Signal'] = (df['Awesome_Oscillator'] < df['AO_SMA']) & (df['Awesome_Oscillator'].shift(1) > df['AO_SMA'].shift(1))\n",
    "\n",
    "    # Convert boolean signals to integers (0 or 1)\n",
    "    df['AO_BUY'] = df['Buy_Signal'].astype(int)\n",
    "    df['AO_SELL'] = df['Sell_Signal'].astype(int)\n",
    "    \n",
    "   \n",
    "    # Drop intermediate columns if not needed\n",
    "    df.drop(['midpoint', 'SMA_5', 'SMA_34', 'AO_SMA'], axis=1, inplace=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    df['5DMA'] = df['CLOSE'].rolling(window=5).mean()\n",
    "    df['8DMA'] = df['CLOSE'].rolling(window=8).mean()\n",
    "    df['13DMA'] = df['CLOSE'].rolling(window=13).mean()\n",
    "    df['21DMA'] = df['CLOSE'].rolling(window=21).mean()\n",
    "    df['20DMA'] = df['CLOSE'].rolling(window=20).mean()\n",
    "    df['50DMA'] = df['CLOSE'].rolling(window=50).mean()\n",
    "     \n",
    "        \n",
    "    df['Bullish_Engulfing'] = ((df['CLOSE'].shift(1) < df['OPEN'].shift(1))  & (df['CLOSE'] > df['OPEN'].shift(1)) & (df['OPEN'] < df['CLOSE'].shift(1)) &  (df['CLOSE'] < df['20DMA'].shift(1))).astype(int) \n",
    "    df['Bearish_Engulfing'] = ((df['CLOSE'].shift(1) > df['OPEN'].shift(1))  & (df['CLOSE'] < df['OPEN'].shift(1)) & (df['OPEN'] > df['CLOSE'].shift(1)) &  (df['CLOSE'] > df['20DMA'].shift(1))).astype(int) \n",
    "\n",
    "\n",
    "\n",
    "    # Calculate the rolling mean (middle line)\n",
    "    df['MA_BB'] = df['CLOSE'].rolling(window=20).mean()\n",
    "    \n",
    "    \n",
    "    df['52week_high'] =df['CLOSE'].shift(1).rolling(window=240).max()\n",
    "    df['52week_low'] = df['CLOSE'].shift(1).rolling(window=240).min()\n",
    "    \n",
    "    df['30day_high'] = df['CLOSE'].shift(1).rolling(window=30).max()\n",
    "    df['30day_low'] = df['CLOSE'].shift(1).rolling(window=30).min()\n",
    "\n",
    "    \n",
    "    df['7day_high'] = df['CLOSE'].shift(1).rolling(window=7).max()\n",
    "    df['7day_low'] =df['CLOSE'].shift(1).rolling(window=7).min()\n",
    "    \n",
    "    df['10day_high'] = df['CLOSE'].shift(1).rolling(window=10).max()\n",
    "    df['10day_low'] =df['CLOSE'].shift(1).rolling(window=10).min()\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Calculate the rolling standard deviation\n",
    "    df['STD_BB'] = df['CLOSE'].rolling(window=20).std()\n",
    "\n",
    "\n",
    "    # Calculate the upper and lower Bollinger Bands\n",
    "    df['Upper_Band_BB'] = df['MA_BB'] + std_dev_multiplier * df['STD_BB']\n",
    "    df['Lower_Band_BB'] = df['MA_BB'] - std_dev_multiplier * df['STD_BB']   \n",
    "    \n",
    "    def wilder_smoothing(data, window):\n",
    "        alpha = 1 / window\n",
    "        smoothed = [data[0]]\n",
    "\n",
    "        for i in range(1, len(data)):\n",
    "            smoothed_value = alpha * data[i] + (1 - alpha) * smoothed[-1]\n",
    "            smoothed.append(smoothed_value)\n",
    "\n",
    "        return pd.Series(smoothed, index=data.index)\n",
    "\n",
    "        # Assuming 'gain' and 'loss' are pandas Series representing the gain and loss values\n",
    "    window = 7\n",
    "    df['delta'] = df['CLOSE'].diff(1)\n",
    "\n",
    "    df['gain'] = (df['delta'].where(df['delta'] > 0, 0)).fillna(0)\n",
    "    df['loss'] = (-df['delta'].where(df['delta'] < 0, 0)).fillna(0)\n",
    "\n",
    "    avg_gain = wilder_smoothing(df['gain'], window)\n",
    "    avg_loss = wilder_smoothing(df['loss'], window)\n",
    "\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    df['RSI_7'] = rsi\n",
    "    df['RSI_7_ma'] = df['RSI_7'].rolling(window=7).mean()\n",
    "\n",
    "    \n",
    "    def wilder_smoothing(data, window):\n",
    "        alpha = 1 / window\n",
    "        smoothed = [data[0]]\n",
    "\n",
    "        for i in range(1, len(data)):\n",
    "            smoothed_value = alpha * data[i] + (1 - alpha) * smoothed[-1]\n",
    "            smoothed.append(smoothed_value)\n",
    "\n",
    "        return pd.Series(smoothed, index=data.index)\n",
    "\n",
    "    window = 14\n",
    "    df['delta'] = df['CLOSE'].diff(1)\n",
    "\n",
    "    df['gain'] = (df['delta'].where(df['delta'] > 0, 0)).fillna(0)\n",
    "    df['loss'] = (-df['delta'].where(df['delta'] < 0, 0)).fillna(0)\n",
    "\n",
    "    avg_gain = wilder_smoothing(df['gain'], window)\n",
    "    avg_loss = wilder_smoothing(df['loss'], window)\n",
    "\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    df['RSI_14'] = rsi\n",
    "    df['RSI_14_ma'] = df['RSI_14'].rolling(window=14).mean()\n",
    "    df['RSI_14_ma5'] = df['RSI_14'].rolling(window=5).mean()\n",
    "    df['RSI_14_ma10'] = df['RSI_14'].rolling(window=10).mean()\n",
    "    df['RSI_14_ma20'] = df['RSI_14'].rolling(window=20).mean()\n",
    "    df['RSI_14_ma50'] = df['RSI_14'].rolling(window=50).mean()\n",
    "\n",
    "\n",
    "    \n",
    "    df['EMA_12'] = df['CLOSE'].ewm(span=12, min_periods=0, adjust=False, ignore_na=False).mean()\n",
    "    df['EMA_26'] = df['CLOSE'].ewm(span=26, min_periods=0, adjust=False, ignore_na=False).mean()\n",
    "    df['MACD'] = df['EMA_12'] - df['EMA_26']\n",
    "    df['Signal_Line'] = df['MACD'].ewm(span=9, min_periods=0, adjust=False, ignore_na=False).mean()\n",
    "    df['MACD_Histogram'] = df['MACD'] - df['Signal_Line']\n",
    "    df['macd_trig'] = ((df['MACD_Histogram'] > 0)  & (df['MACD_Histogram'].shift(1) <= 0) & (df['MACD_Histogram'].shift(2) <0)).astype(int)\n",
    "    df['macd_trig2'] = ((df['MACD_Histogram'] > 0)  & (df['MACD_Histogram'].shift(1) > 0) & (df['MACD_Histogram'].shift(2) <=0)& (df['MACD_Histogram'].shift(3) <0)& (df['MACD_Histogram'].shift(2) > df['MACD_Histogram'].shift(3) )).astype(int)\n",
    "    df['macd_trig_DOWN'] = (((df['MACD_Histogram'] > 0))  & (df['MACD_Histogram'].shift(1) >df['MACD_Histogram']) & (df['MACD_Histogram'].shift(2) <df['MACD_Histogram'].shift(1)) & (df['MACD_Histogram'].shift(3) <df['MACD_Histogram'].shift(2)) & (df['MACD_Histogram'].shift(4) < df['MACD_Histogram'].shift(3)) & (df['MACD_Histogram'].shift(5) < df['MACD_Histogram'].shift(4))).astype(int)\n",
    "    df['macd_trig_UP'] = (((df['MACD_Histogram'] < 0))  & (df['MACD_Histogram'].shift(1) < df['MACD_Histogram']) & (df['MACD_Histogram'].shift(2) > df['MACD_Histogram'].shift(1)) & (df['MACD_Histogram'].shift(3) >df['MACD_Histogram'].shift(2)) & (df['MACD_Histogram'].shift(4) > df['MACD_Histogram'].shift(3)) & (df['MACD_Histogram'].shift(5) > df['MACD_Histogram'].shift(4))).astype(int)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df['BBBreak_upper'] = ((df['CLOSE']  > df['Upper_Band_BB'])  & (df['CLOSE'].shift(1) < df['Upper_Band_BB'].shift(1)) & (df['CLOSE'].shift(2) < df['Upper_Band_BB'].shift(2)) & (df['CLOSE'].shift(3) < df['Upper_Band_BB'].shift(3))).astype(int) \n",
    "    df['BBBreak_lower'] = ((df['CLOSE'] < df['Lower_Band_BB'])  & (df['CLOSE'].shift(1) > df['Lower_Band_BB'].shift(1)) & (df['CLOSE'].shift(2) > df['Lower_Band_BB'].shift(2)) & (df['CLOSE'].shift(3) > df['Lower_Band_BB'].shift(3))).astype(int)\n",
    "\n",
    "    df['BBBreak_upper_tested'] = ((df['HIGH']  > df['Upper_Band_BB'])  & (df['HIGH'].shift(1) < df['Upper_Band_BB'].shift(1)) & (df['HIGH'].shift(2) < df['Upper_Band_BB'].shift(2)) & (df['HIGH'].shift(3) < df['Upper_Band_BB'].shift(3))).astype(int) \n",
    "    df['BBBreak_lower_tested'] = ((df['LOW'] < df['Lower_Band_BB'])  & (df['LOW'].shift(1) > df['Lower_Band_BB'].shift(1)) & (df['LOW'].shift(2) > df['Lower_Band_BB'].shift(2)) & (df['LOW'].shift(3) > df['Lower_Band_BB'].shift(3))).astype(int)\n",
    " \n",
    "    \n",
    "    df['BBBreak_upper_rsi14'] = ((df['CLOSE']  > df['Upper_Band_BB'])  & (df['CLOSE'].shift(1) < df['Upper_Band_BB'].shift(1)) & (df['CLOSE'].shift(2) < df['Upper_Band_BB'].shift(2)) & (df['CLOSE'].shift(3) < df['Upper_Band_BB'].shift(3)) & (df['RSI_14'] > 70)).astype(int) \n",
    "    df['BBBreak_lower_rsi14'] = ((df['CLOSE'] < df['Lower_Band_BB'])  & (df['CLOSE'].shift(1) > df['Lower_Band_BB'].shift(1)) & (df['CLOSE'].shift(2) > df['Lower_Band_BB'].shift(2)) & (df['CLOSE'].shift(3) > df['Lower_Band_BB'].shift(3))& (df['RSI_14'] < 30)).astype(int)\n",
    "\n",
    "\n",
    "    \n",
    "    df['rsi 7 ma break'] = ((df['RSI_7'] > df['RSI_7_ma'])  & (df['RSI_7'].shift(1) < df['RSI_7_ma'].shift(1)) & (df['RSI_7'].shift(2) < df['RSI_7_ma'].shift(2)) & (df['RSI_7'].shift(3) < df['RSI_7_ma'].shift(3))).astype(int)\n",
    "    df['rsi 14 ma break'] = ((df['RSI_14'] > df['RSI_14_ma'])  & (df['RSI_14'].shift(1) < df['RSI_14_ma'].shift(1)) & (df['RSI_14'].shift(2) < df['RSI_14_ma'].shift(2)) & (df['RSI_14'].shift(3) < df['RSI_14_ma'].shift(3))).astype(int)    \n",
    "    df['rsi 14 ma break5_20'] = ((df['RSI_14_ma5'] > df['RSI_14_ma20'])  & (df['RSI_14_ma5'].shift(1) < df['RSI_14_ma20'].shift(1)) & (df['RSI_14_ma5'].shift(2) < df['RSI_14_ma20'].shift(2)) & (df['RSI_14_ma5'].shift(3) < df['RSI_14_ma20'].shift(3))).astype(int)    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    df['rsi 14/7 ma break'] = ((df['RSI_7_ma'] > df['RSI_14_ma'])  & (df['RSI_7_ma'].shift(1) < df['RSI_14_ma'].shift(1)) & (df['RSI_7_ma'].shift(2) < df['RSI_14_ma'].shift(2)) & (df['RSI_7_ma'].shift(3) < df['RSI_14_ma'].shift(3))).astype(int)\n",
    "    df['rsi 7 trig']=  ((df['BBBreak_lower']==1) & (df['RSI_7']<30)).astype(int)\n",
    "    df['rsi 14 trig']=  ((df['BBBreak_lower']==1) & (df['RSI_14']<40)).astype(int)\n",
    "    df['movingAVGcross1_buy'] = ((df['8DMA'] > df['21DMA'])  & (df['8DMA'].shift(1) < df['21DMA'].shift(1)) & (df['8DMA'].shift(2) < df['21DMA'].shift(2)) & (df['8DMA'].shift(3) < df['21DMA'].shift(3))).astype(int)\n",
    "    df['movingAVGcross2_buy'] = ((df['20DMA'] > df['50DMA'])  & (df['20DMA'].shift(1) < df['50DMA'].shift(1)) & (df['20DMA'].shift(2) < df['50DMA'].shift(2)) & (df['20DMA'].shift(3) < df['50DMA'].shift(3))).astype(int)\n",
    "    df['movingAVGcross1_sell'] = ((df['8DMA'] < df['21DMA'])  & (df['8DMA'].shift(1) > df['21DMA'].shift(1)) & (df['8DMA'].shift(2) > df['21DMA'].shift(2)) & (df['8DMA'].shift(3) > df['21DMA'].shift(3))).astype(int)\n",
    "    df['movingAVGcross2_sell'] = ((df['20DMA'] < df['50DMA'])  & (df['20DMA'].shift(1) > df['50DMA'].shift(1)) & (df['20DMA'].shift(2) > df['50DMA'].shift(2)) & (df['20DMA'].shift(3) > df['50DMA'].shift(3))).astype(int)\n",
    "    \n",
    "    df['ABOVE_52week_high'] = ((df['CLOSE']  > df['52week_high']) & (df['CLOSE'].shift(1) < df['52week_high']) & (df['CLOSE'].shift(2) < df['52week_high']) &(df['CLOSE'].shift(3) < df['52week_high'])).astype(int)\n",
    "    df['BELOW_52week_low'] = ((df['CLOSE']  < df['52week_low']) & (df['CLOSE'].shift(1) > df['52week_low']) & (df['CLOSE'].shift(2) > df['52week_low']) & (df['CLOSE'].shift(3) > df['52week_low'])).astype(int) \n",
    "    \n",
    "    df['ABOVE_30day_high'] = ((df['CLOSE']  > df['30day_high']) & (df['CLOSE'].shift(1) < df['30day_high']) & (df['CLOSE'].shift(2) < df['30day_high']) &(df['CLOSE'].shift(3) < df['30day_high'])).astype(int)\n",
    "    df['BELOW_30day_low'] = ((df['CLOSE']  < df['30day_low']) & (df['CLOSE'].shift(1) > df['30day_low']) & (df['CLOSE'].shift(2) > df['30day_low']) &(df['CLOSE'].shift(3) > df['30day_low'])).astype(int)\n",
    "    \n",
    "    df['ABOVE_7day_high'] = ((df['CLOSE']  > df['7day_high']) & (df['CLOSE'].shift(1) < df['7day_high']) & (df['CLOSE'].shift(2) < df['7day_high']) &(df['CLOSE'].shift(3) < df['7day_high'])).astype(int)\n",
    "    df['BELOW_7day_low'] = ((df['CLOSE']  < df['7day_low']) & (df['CLOSE'].shift(1) > df['7day_low']) & (df['CLOSE'].shift(2) > df['7day_low']) &(df['CLOSE'].shift(3) > df['7day_low'])).astype(int)\n",
    "\n",
    "    df['ABOVE_10day_high'] = ((df['CLOSE']  > df['10day_high']) & (df['CLOSE'].shift(1) < df['10day_high']) & (df['CLOSE'].shift(2) < df['10day_high']) &(df['CLOSE'].shift(3) < df['10day_high'])).astype(int)\n",
    "    df['BELOW_10day_low'] = ((df['CLOSE']  < df['10day_low']) & (df['CLOSE'].shift(1) > df['10day_low']) & (df['CLOSE'].shift(2) > df['10day_low']) &(df['CLOSE'].shift(3) > df['10day_low'])).astype(int)\n",
    "     \n",
    "    df['sure_BUY']= ((df['CLOSE']  > df['OPEN']) & (df['CLOSE']< df['Lower_Band_BB'])).astype(int)\n",
    "    df['sure_SELL']= ((df['CLOSE']  < df['OPEN']) & (df['CLOSE']> df['Upper_Band_BB'])).astype(int)\n",
    "\n",
    "    \n",
    "    dfs1_filtered[symbol] = df \n",
    "\n",
    "    \n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'dfs1' is the dictionary of data frames\n",
    "# Initialize an empty list to store the data frames\n",
    "dfs_list = []\n",
    "combined_df=pd.DataFrame()\n",
    "# Iterate over each data frame in the dictionary and append it to the list\n",
    "for df in dfs1_filtered.values():\n",
    "    dfs_list.append(df)\n",
    "\n",
    "# Concatenate all data frames in the list\n",
    "combined_df = pd.concat(dfs_list)\n",
    "\n",
    "# Reset the index to avoid duplicate index values\n",
    "combined_df = combined_df.reset_index(drop=False)\n",
    "\n",
    "\n",
    "#selected_column=['TIMESTAMP','SYMBOL_y','RSI_7','RSI_14','CLOSE','BBBreak_upper','BBBreak_lower','BBBreak_upper_50','BBBreak_lower_50','BBBreak_upper_7','BBBreak_lower_7','TEST_50','TEST_7','max_15DAY','max_30DAY','15 greater than abs 4%','30 greater than abs 4%','15 greater than 4%','5 greater than 1%']  # Replace with your desired column names\n",
    "selected_column=['TIMESTAMP',\n",
    "                 'SYMBOL',\n",
    "                 'RSI_7',\n",
    "                 'RSI_14',\n",
    "                 'CLOSE',\n",
    "                 'Latest_Close_Price',\n",
    "                 'Percentage_Difference',\n",
    "                 'Bullish_Engulfing',\n",
    "                 'BBBreak_upper_rsi14',\n",
    "                 'BBBreak_lower_rsi14',\n",
    "                 'sure_BUY',\n",
    "                 'sure_SELL',\n",
    "                 'Bearish_Engulfing',\n",
    "                 'AO_BUY',\n",
    "                 'AO_SELL',\n",
    "                 'macd_trig_DOWN',\n",
    "                 'macd_trig_UP',\n",
    "                 'BBBreak_upper',\n",
    "                 'BBBreak_lower',\n",
    "                 'BBBreak_upper_tested',\n",
    "                 'BBBreak_lower_tested',\n",
    "                 'rsi 7 ma break',\n",
    "                 'rsi 14 ma break',\n",
    "                 'rsi 14/7 ma break',\n",
    "                 'rsi 7 trig',\n",
    "                 'rsi 14 trig',\n",
    "                 'movingAVGcross1_buy',\n",
    "                 'movingAVGcross2_buy',\n",
    "                 'movingAVGcross1_sell',\n",
    "                 'movingAVGcross2_sell',\n",
    "                 'ABOVE_52week_high',\n",
    "                 'BELOW_52week_low',\n",
    "                 'ABOVE_30day_high',\n",
    "                 'BELOW_30day_low',\n",
    "                 'ABOVE_7day_high',\n",
    "                 'BELOW_7day_low',\n",
    "                 'ABOVE_10day_high',\n",
    "                 'BELOW_10day_low',\n",
    "                 \n",
    "                 \n",
    "                 ]  # Replace with your desired column names\n",
    "selected_df = combined_df[selected_column]\n",
    "selected_df.to_csv('D:/4.Daily_stocks/Full_stocks.csv')\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure the directory exists, if not create it\n",
    "save_path = 'D:/4.Daily_stocks'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "# Sample dataframe (you'll have your dataframe here)\n",
    "# df = pd.read_csv('your_file.csv')\n",
    "\n",
    "# List of columns to filter\n",
    "columns_to_filter = ['BBBreak_upper_rsi14',\n",
    "                     'BBBreak_lower_rsi14',\n",
    "                     'sure_BUY',\n",
    "                     'sure_SELL',\n",
    "                     'Bullish_Engulfing',\n",
    "                     'Bearish_Engulfing',\n",
    "                     'AO_BUY',\n",
    "                     'AO_SELL',\n",
    "                     'macd_trig_DOWN', \n",
    "                     'macd_trig_UP',\n",
    "                     'BBBreak_upper', \n",
    "                     'BBBreak_lower', \n",
    "                     'BBBreak_upper_tested',\n",
    "                     'BBBreak_lower_tested', \n",
    "                     'movingAVGcross1_buy',\n",
    "                     'movingAVGcross2_buy', \n",
    "                     'movingAVGcross1_sell', \n",
    "                     'movingAVGcross2_sell',\n",
    "                     'ABOVE_52week_high', \n",
    "                     'BELOW_52week_low', \n",
    "                     'ABOVE_30day_high',\n",
    "                     'BELOW_30day_low',\n",
    "                     'ABOVE_7day_high', 'BELOW_7day_low', \n",
    "                     'ABOVE_10day_high', 'BELOW_10day_low']\n",
    "\n",
    "# Loop through each specified column\n",
    "for column in columns_to_filter:\n",
    "    # Filter rows where the column value is 1\n",
    "    filtered_df = selected_df[selected_df[column] == 1]\n",
    "    \n",
    "    # If the filtered dataframe is not empty and has a 'TIMESTAMP' and 'CLOSE' column, extract required columns\n",
    "    if not filtered_df.empty and 'TIMESTAMP' in filtered_df.columns and 'CLOSE' in filtered_df.columns:\n",
    "        # Extracting the latest close value\n",
    "        latest_close = filtered_df['CLOSE'].iloc[-1]\n",
    "       # Select required columns\n",
    "        filtered_df_final = filtered_df[['TIMESTAMP', 'SYMBOL','CLOSE','Latest_Close_Price','Percentage_Difference']]\n",
    "        \n",
    "        # Sort by 'TIMESTAMP' in descending order (newest to oldest)\n",
    "        filtered_df_final_sorted = filtered_df_final.sort_values(by='TIMESTAMP', ascending=False)\n",
    "        \n",
    "        # Define the full file path\n",
    "        file_path = os.path.join(save_path, f\"{column.replace(' ', '_')}_filtered.csv\")\n",
    "        \n",
    "        # Save the sorted dataframe with required columns to the specified directory\n",
    "        filtered_df_final_sorted.to_csv(file_path, index=False)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure the directory exists, if not create it\n",
    "save_path = 'D:/4.Daily_stocks/'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "# Sample dataframe (you'll have your dataframe here)\n",
    "# selected_df = pd.read_csv('your_file.csv')\n",
    "\n",
    "# List of columns to filter\n",
    "columns_to_filter = ['sure_BUY','sure_SELL','Bullish_Engulfing','Bearish_Engulfing','AO_BUY','AO_SELL','macd_trig_DOWN', 'macd_trig_UP', 'BBBreak_upper', 'BBBreak_lower', \n",
    "                     'BBBreak_upper_tested', 'BBBreak_lower_tested', 'rsi 7 ma break', \n",
    "                     'rsi 14 ma break', 'rsi 14/7 ma break', 'rsi 7 trig', 'rsi 14 trig', \n",
    "                     'movingAVGcross1_buy', 'movingAVGcross2_buy', 'movingAVGcross1_sell', \n",
    "                     'movingAVGcross2_sell', 'ABOVE_52week_high', 'BELOW_52week_low', \n",
    "                     'ABOVE_30day_high', 'BELOW_30day_low', 'ABOVE_7day_high', 'BELOW_7day_low', \n",
    "                     'ABOVE_10day_high', 'BELOW_10day_low']\n",
    "\n",
    "# Create Excel Writer object\n",
    "excel_path = os.path.join(save_path, \"filtered_data.xlsx\")\n",
    "\n",
    "# Dictionary to hold dataframes\n",
    "dfs_to_save = {}\n",
    "\n",
    "# Loop through each specified column\n",
    "for column in columns_to_filter:\n",
    "    # Filter rows where the column value is 1\n",
    "    filtered_df = selected_df[selected_df[column] == 1]\n",
    "    \n",
    "    # If the filtered dataframe is not empty and has required columns\n",
    "    if not filtered_df.empty and 'TIMESTAMP' in filtered_df.columns and 'CLOSE' in filtered_df.columns:\n",
    "        # Extract the latest close value\n",
    "        latest_close = filtered_df['CLOSE'].iloc[-1]\n",
    "        \n",
    "        # Select required columns\n",
    "        filtered_df_final = filtered_df[['TIMESTAMP', 'SYMBOL', 'CLOSE', 'Latest_Close_Price', 'Percentage_Difference']]\n",
    "        \n",
    "        # Sort by 'TIMESTAMP' in descending order (newest to oldest)\n",
    "        filtered_df_final_sorted = filtered_df_final.sort_values(by='TIMESTAMP', ascending=False)\n",
    "        \n",
    "        # Replace invalid characters in the sheet name\n",
    "        sheet_name = column.replace(' ', '_').replace('/', '_')  # Replacing '/' with '_'\n",
    "        \n",
    "        # Add the sorted dataframe to the dictionary with modified sheet name as the key\n",
    "        dfs_to_save[sheet_name] = filtered_df_final_sorted\n",
    "\n",
    "# Save dataframes to Excel file with each dataframe as a separate sheet\n",
    "with pd.ExcelWriter(excel_path) as writer:\n",
    "    for sheet_name, df_to_save in dfs_to_save.items():\n",
    "        # Convert 'TIMESTAMP' to datetime format\n",
    "        df_to_save['TIMESTAMP'] = pd.to_datetime(df_to_save['TIMESTAMP'])\n",
    "        \n",
    "        # Format 'TIMESTAMP' to only include year, month, and day\n",
    "        df_to_save['TIMESTAMP'] = df_to_save['TIMESTAMP'].dt.strftime('%d-%m-%Y')\n",
    "        \n",
    "        # Save the dataframe to Excel with the formatted TIMESTAMP column\n",
    "        df_to_save.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
